# LinChat
ğŸŒŸ Vision: The Best Deep Research Product

Your goal:

â†’ Build the best AI-powered deep research co-pilot that:

âœ… Handles complex research questions
âœ… Combines:

Private documents (PDFs, Word, Excel, PPT, etc.)
Live web data (via browsing & scraping)
âœ… Synthesizes insights into:

Structured reports
Slide decks
Tables
Charts
PDF exports
Excel files
âœ… Provides traceable citations for every claim

âœ… Works for teams (~5 users) with:

Collaboration
Document sharing
Access control
âœ… Ensures data privacy & security

âœ… Analysis is a backend process.

Users care only about results
Not the code or tech used
â†’ A true virtual research analyst for professionals.

ğŸ† Market Opportunity

Gap in the market:

Consumer chatbots â†’ shallow, lack citations
Enterprise tools (e.g. AlphaSense) â†’ expensive, inaccessible to SMBs
No solution today that:
Synthesizes multi-source insights
Handles private + public data seamlessly
Produces structured, export-ready deliverables
Is affordable and private
â†’ Huge mid-market opportunity:

Consultants
Analysts
NGOs
Strategy teams
Knowledge workers
Potential TAM â†’ hundreds of millions globally.

ğŸ’¡ Key Product Differentiators

âœ… 1. Multi-Source Synthesis
Fuses insights from:
Private documents
Web searches
Proprietary data
No other tool bridges both worlds this deeply.
âœ… 2. Live Web Browsing
Scrapes web in real time
Extracts text, tables
Updates research with fresh info
â†’ Beyond static knowledge bases like ChatGPT.

âœ… 3. Citations & Traceability
Every claim linked to:
Document snippets
URLs
Uses advanced techniques like:
ContextCite
Chunk-level tagging
Users can click to verify sources.
âœ… 4. Structured Outputs
Not just chat replies.
Generates:
Executive summaries
Bullet lists
Tables
Charts
Slide decks
All exportable:
PDF
Excel
PowerPoint
âœ… 5. Excel & Data Analysis
Upload Excel â†’ parse into structured data
Run analysis:
CAGR
Summaries
Charts
Merges across sheets
Export:
New Excel files
Charts as images
All seamless â†’ user never has to see code.
âœ… 6. Backend Analysis Engine
Users want speed and results â†’ not code.
Analysis implemented as:
Rust services (e.g. Polars for DataFrames)
High-speed charting
Result:
Blazing fast analysis
Low resource costs
Optionally expose code downloads for enterprise clients â†’ but hidden for regular users.
âœ… 7. Collaboration for Teams
Team-based permissions:
Private vs shared docs
Versioning
Shared research threads
Centralized knowledge hub
Audit trails for data security
âœ… 8. Privacy-First Design
Self-hostable or private cloud
No user data leaks to public APIs
Encryption at rest & in transit
Full compliance (SOC2, GDPR, etc.)
â†’ A trusted research assistant.

ğŸ›  Technical Blueprint

LLM Layer
Large-context models:
LLaMA-3-70B
Mistral-XXB
Open-source â†’ avoid vendor lock-in
RAG pipeline:
Document retrieval
Chunking
Context injection
Web Browsing
Live scraping:
Playwright
Selenium
Scraped pages converted to:
Clean text
Embedded tables
Indexed in vector DB alongside private docs.
Vector Database
ChromaDB or Qdrant
Holds:
Document embeddings
Web page chunks
Enables semantic search.
Analysis Engine
Backend microservice:
Rust + Polars:
~10-30x faster than pandas
Low latency
Computes:
Aggregations
Charts
Statistical analyses
Returns:
Images (charts)
Tables
Summaries
Structured Output & Export
LLM generates:
JSON schemas for reports
Slide structures
Backend converts:
Markdown/HTML â†’ PDF (WeasyPrint)
DataFrames â†’ Excel
Slide JSON â†’ PowerPoint
Frontend UI
Upload docs
Ask complex research questions
View:
Summaries
Charts
Data tables
Export:
PDF
Excel
PPT

## Getting Started

This repository contains the initial code for a FastAPI service that integrates with [OpenRouter](https://openrouter.ai/) for language model access. To run the development server:

```bash
pip install -r requirements.txt
export ADMIN_PASSWORD="your-password"
uvicorn app.main:app --reload
```

The admin interface is protected via HTTP basic auth. The default username is `admin` and the password is read from the `admin_password` field in `app/config.json` or the `ADMIN_PASSWORD` environment variable when first run. Navigate to `/admin` to update the OpenRouter API key used for LLM queries.
You can also set the model used for completions by editing the `openrouter_model` value in `app/config.json` or via the admin page.
